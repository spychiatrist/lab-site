<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>News on Cornell RPAL</title>
    <link>https://rpal.cs.cornell.edu/news/index.xml</link>
    <description>Recent content in News on Cornell RPAL</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 23 Nov 2017 23:47:43 -0500</lastBuildDate>
    <atom:link href="https://rpal.cs.cornell.edu/news/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Paper Accepted to HRI 2018</title>
      <link>https://rpal.cs.cornell.edu/news/hri2018/</link>
      <pubDate>Thu, 23 Nov 2017 23:47:43 -0500</pubDate>
      
      <guid>https://rpal.cs.cornell.edu/news/hri2018/</guid>
      <description>&lt;p&gt;The paper &amp;ldquo;Social Momentum: A Framework for Legible Navigation in Dynamic Multi-Agent Environments&amp;rdquo;, by &lt;a href=&#34;https://rpal.cs.cornell.edu/people/chris/&#34;&gt;Christoforos Mavrogiannis&lt;/a&gt;, &lt;a href=&#34;https://rpal.cs.cornell.edu/people/wil/&#34;&gt;Wil Thomason&lt;/a&gt;, and &lt;a href=&#34;https://rpal.cs.cornell.edu/people/ross/&#34;&gt;Ross Knepper&lt;/a&gt;, has been accepted to &lt;a href=&#34;http://humanrobotinteraction.org/2018/&#34;&gt;&lt;strong&gt;HRI 2018&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;From the paper:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Intent-expressive robot motion has been shown to result in increased efficiency and reduced
planning efforts for human or robot partners in implicitly or explicitly collaborative
scenarios. Existing frameworks for generating intent-expressive robot behaviors have typically
focused on applications in static or structured environments. Under such settings, emphasis is
placed towards communicating the robot&amp;rsquo;s intended final configuration to other agents. However,
in dynamic, unstructured and multi-agent domains, such as pedestrian environments, knowledge of
the robot&amp;rsquo;s final configuration is not sufficiently informative, as it completely ignores the
complex dynamics of interaction among agents. To address this problem, we focus on the
generation of motion that communicates an agent&amp;rsquo;s intention toward a socially compliant
collision avoidance strategy rather than its destination. We contribute a planning framework
that estimates the intended avoidance strategies of others, superimposes them, and generates an
expressive, socially compliant robot action that reinforces the expectations of others regarding
the scene evolution. This action facilitates inference and decision making for everyone, as
illustrated in the simplified topological pattern of agents&amp;rsquo; trajectories at the end of the
execution. Extensive simulations demonstrate that our framework consistently achieves
significantly lower topological complexity, compared against common benchmark approaches in the
area of multi-agent collision avoidance. The significance of this result for real world
applications is demonstrated by a user study that revealed statistical evidence suggesting that
multi-agent trajectories of lower topological complexity tend to enable observers to infer the
intentions of actors more quickly and more accurately.&lt;/p&gt;
&lt;/blockquote&gt;
</description>
    </item>
    
    <item>
      <title>Paper Accepted to IROS 2017</title>
      <link>https://rpal.cs.cornell.edu/news/iros2017_paper/</link>
      <pubDate>Sat, 29 Jul 2017 23:47:43 -0500</pubDate>
      
      <guid>https://rpal.cs.cornell.edu/news/iros2017_paper/</guid>
      <description>&lt;p&gt;The paper &amp;ldquo;Socially Competent Navigation Planning by Deep Learning of
Multi-Agent Path Topologies&amp;rdquo;, by &lt;a href=&#34;https://rpal.cs.cornell.edu/people/chris/&#34;&gt;Christoforos Mavrogiannis&lt;/a&gt;, &lt;a href=&#34;https://rpal.cs.cornell.edu/people/valts/&#34;&gt;Valts
Blukis&lt;/a&gt;, and &lt;a href=&#34;https://rpal.cs.cornell.edu/people/ross/&#34;&gt;Ross Knepper&lt;/a&gt; has been
accepted to &lt;strong&gt;&lt;a href=&#34;http://iros2017.org&#34;&gt;IROS 2017&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;From the paper:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;We present a novel, data-driven framework for planning socially competent robot behaviors in
crowded environments. The core of our approach is a topological model of collective navigation
behaviors, based on braid groups. This model constitutes the basis for the design of a
human-inspired probabilistic inference mechanism that predicts the topology of multiple agents’
future trajectories, given observations of the context. We derive an approximation of this
mechanism by employing a neural network learning architecture on synthetic data of collective
navigation behaviors. Our planner makes use of this mechanism as a tool for interpreting the
context and understanding what future behaviors are in compliance with it. The planning agent
makes use of this understanding to determine a personal action that contributes to the context
in the most clear way possible, while ensuring progress to its destination. Our simulations
provide evidence that our planning framework results in socially competent navigation behaviors
not only for the planning agent, but also for interacting naive agents. Performance benefits
include (1) early conflict resolutions and (2) faster uncertainty decrease for the other agents
in the scene.&lt;/p&gt;
&lt;/blockquote&gt;
</description>
    </item>
    
    <item>
      <title>Ph.D. Student Wil Thomason Receives NSF GRFP and NDSEG Fellowship</title>
      <link>https://rpal.cs.cornell.edu/news/thomason_grfp/</link>
      <pubDate>Tue, 11 Apr 2017 17:25:09 -0500</pubDate>
      
      <guid>https://rpal.cs.cornell.edu/news/thomason_grfp/</guid>
      <description>&lt;p&gt;Second-year Ph.D. student &lt;a href=&#34;https://rpal.cs.cornell.edu/people/wil/&#34;&gt;Wil Thomason&lt;/a&gt; was awarded a four-year
fellowship through the &lt;a href=&#34;https://ndseg.asee.org/&#34;&gt;National Defense Science and Engineering Graduate
Fellowship&lt;/a&gt;. He also received a three-year fellowship through the National
Science Foundation&amp;rsquo;s &lt;a href=&#34;https://www.nsf.gov/news/news_summ.jsp?cntn_id=191361&amp;amp;org=NSF&amp;amp;from=news&#34;&gt;Graduate Research Fellowship
Program&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Paper Nominated for Best Paper Award at HRI 2017</title>
      <link>https://rpal.cs.cornell.edu/news/hri2017_nominated_best_paper/</link>
      <pubDate>Tue, 07 Mar 2017 17:25:09 -0500</pubDate>
      
      <guid>https://rpal.cs.cornell.edu/news/hri2017_nominated_best_paper/</guid>
      <description>&lt;p&gt;The paper &amp;ldquo;Implicit Communication in a Joint Action&amp;rdquo;, by &lt;a href=&#34;https://rpal.cs.cornell.edu/people/ross/&#34;&gt;Ross Knepper&lt;/a&gt;,
&lt;a href=&#34;https://rpal.cs.cornell.edu/people/chris/&#34;&gt;Christoforos Mavrogiannis&lt;/a&gt;, &lt;a href=&#34;https://rpal.cs.cornell.edu/people/julia/&#34;&gt;Julia Proft&lt;/a&gt;,
and &lt;a href=&#34;https://rpal.cs.cornell.edu/people/claire/&#34;&gt;Claire Liang&lt;/a&gt;, has been nominated for a &lt;strong&gt;Best Paper Award&lt;/strong&gt; at
&lt;a href=&#34;http://humanrobotinteraction.org/2017/&#34;&gt;&lt;strong&gt;HRI 2017&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;For more on the paper, please see &lt;a href=&#34;https://rpal.cs.cornell.edu/news/hri2017/&#34;&gt;the announcement of its acceptance&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Paper Accepted to HRI 2017</title>
      <link>https://rpal.cs.cornell.edu/news/hri2017/</link>
      <pubDate>Tue, 24 Jan 2017 23:47:43 -0500</pubDate>
      
      <guid>https://rpal.cs.cornell.edu/news/hri2017/</guid>
      <description>&lt;p&gt;The paper &amp;ldquo;Implicit Communication in a Joint Action&amp;rdquo;, by &lt;a href=&#34;https://rpal.cs.cornell.edu/people/ross/&#34;&gt;Ross Knepper&lt;/a&gt;,
&lt;a href=&#34;https://rpal.cs.cornell.edu/people/chris/&#34;&gt;Christoforos Mavrogiannis&lt;/a&gt;, &lt;a href=&#34;https://rpal.cs.cornell.edu/people/julia/&#34;&gt;Julia Proft&lt;/a&gt;,
and &lt;a href=&#34;https://rpal.cs.cornell.edu/people/claire/&#34;&gt;Claire Liang&lt;/a&gt;, has been accepted to &lt;a href=&#34;http://humanrobotinteraction.org/2017/&#34;&gt;&lt;strong&gt;HRI
2017&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;From the paper:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Actions performed in the context of a joint activity comprise two aspects: functional and
communicative. The functional component achieves the goal of the action, whereas its
communicative component, when present, expresses some information to the actor’s partners in the
joint activity. The interpretation of such communication requires leveraging information that is
public to all participants, known as common ground. Much of human communication is performed
through this implicit mechanism, and humans cannot help but infer some meaning — whether or not
it was intended by the actor — from most actions. Robots must be cognizant of how their actions
will be interpreted in context. We present a framework for robots to utilize this communicative
channel on top of normal functional actions to work more effectively with human partners. We
consider the role of the actor and the observer, both individually and jointly, in implicit
communication, as well as the effects of timing. We also show how the framework maps onto
various modes of action, including natural language and motion. We consider these modes of
action in various human-robot interaction domains, including social navigation and collaborative
assembly.&lt;/p&gt;
&lt;/blockquote&gt;
</description>
    </item>
    
    <item>
      <title>Paper Presented at WAFR 2016</title>
      <link>https://rpal.cs.cornell.edu/news/wafr2016/</link>
      <pubDate>Tue, 20 Dec 2016 23:47:43 -0500</pubDate>
      
      <guid>https://rpal.cs.cornell.edu/news/wafr2016/</guid>
      <description>&lt;p&gt;The paper &lt;a href=&#34;http://wafr.org/papers/WAFR_2016_paper_117.pdf&#34;&gt;&amp;ldquo;Decentralized Multi-Agent Navigation Planning with
Braids&amp;rdquo;&lt;/a&gt;, by &lt;a href=&#34;https://rpal.cs.cornell.edu/people/chris/&#34;&gt;Christoforos Mavrogiannis&lt;/a&gt; and &lt;a href=&#34;https://rpal.cs.cornell.edu/people/ross/&#34;&gt;Ross Knepper&lt;/a&gt;, was presented at &lt;a href=&#34;http://www.wafr.org/&#34;&gt;&lt;strong&gt;WAFR
2016&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;From the paper:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;We present a novel planning framework for navigation in dynamic,
multi-agent environments with no explicit communication among agents, such as
pedestrian scenes. Inspired by the collaborative nature of human navigation, our
approach treats the problem as a coordination game, in which players coordinate
to avoid each other as they move towards their destinations. We explicitly encode
the concept of coordination into the agents’ decision making process through a
novel inference mechanism about future joint strategies of avoidance. We represent
joint strategies as equivalence classes of topological trajectory patterns using
the formalism of braids. This topological representation naturally generalizes to
any number of agents and provides the advantage of adaptability to different environments,
in contrast to the majority of existing approaches. At every round,
the agents simultaneously decide on their next action that contributes collision-free
progress towards their destination but also towards a global joint strategy
that appears to be in compliance with all agents’ preferences, as inferred from
their past behaviors. This policy leads to a smooth and rapid uncertainty decrease
regarding the emerging joint strategy that is promising for real world scenarios.
Simulation results highlight the importance of reasoning about joint strategies
and demonstrate the efficacy of our approach.&lt;/p&gt;
&lt;/blockquote&gt;
</description>
    </item>
    
  </channel>
</rss>